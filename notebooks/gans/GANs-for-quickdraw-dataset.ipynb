{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Processing Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "# os.environ['CUDA_VISIBLE_DEVICE'] = '0' # leave empty to run on CPUs only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.layers import Activation, Reshape, Conv2DTranspose, UpSampling2D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras_contrib.layers.advanced_activations import SineReLU\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = '../../quickdraw_data/apple.npy'\n",
    "data = np.load(input_images)\n",
    "\n",
    "print(data.shape)\n",
    "print(data[4242])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It needs to be normalised, since the current range is from 0 to 255.\n",
    "data = data / 255\n",
    "\n",
    "# Quickdraw images are 28x28 and greyscale. To use it with CNNs, we have to reshape the images to be 28x28x1\n",
    "img_w, img_h, channels = 28, 28, 1\n",
    "data = np.reshape(data, (data.shape[0], img_w, img_h, channels))\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[4242, :, :, 0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Discriminator NetworkÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those parameters could be parameterised.\n",
    "def discriminator_builder(filters=64, kernel=5, drop=0.4):\n",
    "    inputs = Input((img_w, img_h, channels))\n",
    "    \n",
    "    X = Conv2D(filters, kernel_size=kernel, strides=2, padding='same')(inputs)\n",
    "    X = SineReLU(0.0025)(X)\n",
    "    X = Dropout(drop)(X)\n",
    "    \n",
    "    X = Conv2D(filters * 2, kernel_size=kernel, strides=2, padding='same')(X)\n",
    "    X = SineReLU(0.0025)(X)\n",
    "    X = Dropout(drop)(X)\n",
    "\n",
    "    X = Conv2D(filters * 4, kernel_size=kernel, strides=2, padding='same')(X)\n",
    "    X = SineReLU(0.0025)(X)\n",
    "    X = Dropout(drop)(X)\n",
    "\n",
    "    X = Conv2D(filters * 8, kernel_size=kernel, strides=1, padding='same')(X)\n",
    "    X = SineReLU(0.0025)(X)\n",
    "    X = Dropout(drop)(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(drop)(X)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = discriminator_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to compile the discriminator model because it's going to validate the input images.\n",
    "\n",
    "d_model = Sequential()\n",
    "d_model.add(discriminator)\n",
    "\n",
    "d_model.compile(loss='binary_crossentropy',\n",
    "                     optimizer=RMSprop(lr=0.0008, decay=6e-8, clipvalue=1.0),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_builder(latent_space=100, filters=64, kernel=5, drop=0.4):\n",
    "    inputs = Input((latent_space,))\n",
    "    \n",
    "    # The 64 here will is needed because it will represent the amount of filters in the D-Conv Layer.\n",
    "    X = Dense(7 * 7 * 64)(inputs)\n",
    "    X = BatchNormalization(momentum=0.9)(X)\n",
    "    X = ReLUs(epsilon=0.0025)(X)\n",
    "    X = Reshape((7, 7, 64))(X)\n",
    "    X = Dropout(drop)(X)\n",
    "    \n",
    "    # De-Convolutional Layer\n",
    "    X = UpSampling2D()(X)\n",
    "    # Activation is set to None because we want to control when things happen. In that case, we want\n",
    "    # BatchNormalization to happen before the activation.\n",
    "    X = Conv2DTranspose(int(filters / 2), kernel, padding='same')(X)\n",
    "    X = BatchNormalization(momentum=0.9)(X)\n",
    "    X = ReLUs(epsilon=0.0025)(X)\n",
    "    \n",
    "    X = UpSampling2D()(X)\n",
    "    X = Conv2DTranspose(int(filters / 4), kernel, padding='same')(X)\n",
    "    X = BatchNormalization(momentum=0.9)(X)\n",
    "    X = ReLUs(epsilon=0.0025)(X)\n",
    "\n",
    "    X = Conv2DTranspose(int(filters / 8), kernel, padding='same')(X)\n",
    "    X = BatchNormalization(momentum=0.9)(X)\n",
    "    X = ReLUs(epsilon=0.0025)(X)\n",
    "    \n",
    "    X = Conv2DTranspose(int(filters / 16), kernel, padding='same')(X)\n",
    "    X = BatchNormalization(momentum=0.9)(X)\n",
    "    X = ReLUs(epsilon=0.0025)(X)\n",
    "    \n",
    "    # Cnovolutional Layer\n",
    "    # 1 filter convolution layer because it will represent a full 28x28x1 image.\n",
    "    # Using 'sigmoid' here because we want this 28x28x1 image to have pixels between 0 and 1.\n",
    "    output = Conv2D(1, kernel, padding='same', activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need to compile the generator model as it is part of the adversarial model.\n",
    "generator = generator_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Adversarial Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_builder(latent_space=100):\n",
    "    inputs = Input((latent_space,))\n",
    "    \n",
    "    X = generator(inputs)\n",
    "    output = discriminator(X)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model = adversarial_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer arguments are half of what we have in the Discriminator Network.\n",
    "adversarial_model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=0.0004, decay=3e-8, clipvalue=1.0),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to enable/disable trainability in the discriminator. For instance, when runing only\n",
    "# The discriminator, based on a real input, it should be trainable (i.e. the weights should change). However,\n",
    "# when the input is coming from the generator network, we do not want to train the Discrimintor. So, the weigths\n",
    "# should be frozen.\n",
    "def set_trainability(model, should_train=False):\n",
    "    model.trainable = should_train\n",
    "    for l in model.layers:\n",
    "        l.trainable = should_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(latent_space=100, epochs=2000, batch_size=128):\n",
    "    sample_size = 16\n",
    "    \n",
    "    d_metrics = []\n",
    "    a_metrics = []\n",
    "    \n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if i % 50 == 0:\n",
    "            print('Epoch --> %s...' % str(i))\n",
    "        \n",
    "        # Get random 128 (batch_size) real images\n",
    "        random_real_imgs = data[np.random.choice(data.shape[0], batch_size, replace=False)]\n",
    "        fake_imgs = generator.predict_on_batch(np.random.uniform(-1.0, 1.0, size=[batch_size, latent_space]))\n",
    "        \n",
    "        X = np.concatenate((random_real_imgs, fake_imgs))\n",
    "        y = np.ones([2 * batch_size, 1])\n",
    "        # Make the second half of the y vector 0, because they are all fake images.\n",
    "        y[batch_size:, :] = 0\n",
    "\n",
    "        set_trainability(d_model, should_train=True)\n",
    "        \n",
    "        metrics = d_model.train_on_batch(X, y)\n",
    "        d_metrics.append(metrics)\n",
    "        running_d_loss += d_metrics[-1][0]\n",
    "        running_d_acc += d_metrics[-1][1]\n",
    "        \n",
    "        set_trainability(d_model)\n",
    "        \n",
    "        A_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_space])\n",
    "        y_noise = np.ones([batch_size, 1])\n",
    "        \n",
    "        a_metrics.append(adversarial_model.train_on_batch(A_noise, y_noise))\n",
    "        running_a_loss += a_metrics[-1][0]\n",
    "        running_a_acc += a_metrics[-1][1]\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "\n",
    "            print('Epoch #{}'.format(i + 1))\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, running_d_loss / i, running_d_acc / i)\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, running_a_loss / i, running_a_acc / i)\n",
    "            print(log_mesg)\n",
    "\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[sample_size, latent_space])\n",
    "            gen_imgs = generator.predict_on_batch(noise)\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "\n",
    "            for k in range(gen_imgs.shape[0]):\n",
    "                plt.subplot(4, 4, k + 1)\n",
    "                plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return a_metrics, d_metrics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_metrics_complete, d_metrics_complete = train(epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Generator': [metric[0] for metric in a_metrics_complete],\n",
    "        'Discriminator': [metric[0] for metric in d_metrics_complete],\n",
    "    }\n",
    ").plot(title='Training Loss', logy=True)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Generator': [metric[1] for metric in a_metrics_complete],\n",
    "        'Discriminator': [metric[1] for metric in d_metrics_complete],\n",
    "    }\n",
    ").plot(title='Training Accuracy')\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
