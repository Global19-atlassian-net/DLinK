{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Iceberg Detection Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a ResNet with ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"kaggle/datasets/iceberg/train.json\")\n",
    "test = pd.read_json(\"kaggle/datasets/iceberg/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "\n",
    "X_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1 + X_band_2) / 2)[:, :, :, np.newaxis]], axis = -1)\n",
    "\n",
    "target_train = train['is_iceberg']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, target_train, random_state = 42, train_size = 0.75)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, main_path_shape, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    main_path_shape -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    # Kernel Size is (1, 1), or just 1\n",
    "    # Default strides is (1, 1)\n",
    "    X = Conv2D(F1, kernel_size = 1, padding = 'valid', name = conv_name_base + '2a', kernel_initializer = 'he_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('ReLU_s')(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    # Kernel Size is (main_path_shape, main_path_shape)\n",
    "    # Default strides is (1, 1)\n",
    "    X = Conv2D(F2, kernel_size = main_path_shape, padding = 'same', name = conv_name_base + '2b', kernel_initializer = 'he_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('ReLU_s')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    # Default strides is (1, 1)\n",
    "    X = Conv2D(F3, kernel_size = 1, padding = 'valid', name = conv_name_base + '2c', kernel_initializer = 'he_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('ReLU_s')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, main_path_shape, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    main_path_shape -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, kernel_size = 1, strides = s, name = conv_name_base + '2a', kernel_initializer = 'he_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('ReLU_s')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(F2, kernel_size = main_path_shape, padding = 'same', name = conv_name_base + '2b', kernel_initializer = 'he_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('ReLU_s')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(F3, kernel_size = 1, padding = 'valid', name = conv_name_base + '2c', kernel_initializer = 'he_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, kernel_size = 1, strides = s, padding = 'valid', name = conv_name_base + '1', kernel_initializer = 'he_uniform')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('ReLU_s')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Custom Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "def relus(Z):\n",
    "    e_param = 0.001\n",
    "    pi = K.variable((3.14))\n",
    "    m = e_param + (K.sigmoid(K.sin(Z)) - K.sigmoid(K.cos(Z)) * K.exp(K.sqrt(pi)))\n",
    "    A = K.maximum(m, Z)\n",
    "    return A\n",
    "\n",
    "get_custom_objects().update({'ReLU_s': Activation(relus)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(input_shape = (75, 75, 3)):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK -> CONVBLOCK -> IDBLOCK\n",
    "    -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FC -> SOFTMAX\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(16, kernel_size = 5, strides = 2, name = 'conv1', kernel_initializer = 'he_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('ReLU_s')(X)\n",
    "    X = MaxPooling2D(pool_size = 3, strides = (2, 2))(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [32, 64, 64], stage = 2, block = 'a', s = 1)\n",
    "    X = identity_block(X, 3, [32, 64, 64], stage = 2, block = 'b')\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [64, 64, 128], stage = 3, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [64, 64, 128], stage = 3, block = 'b')\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [128, 128, 256], stage = 4, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='d')\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='e')\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [265, 256, 512], stage = 5, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'b')\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'c')\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'd')\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'e')\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = MaxPooling2D(pool_size = 1, name = 'max_pool')(X)\n",
    "    \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(n_classes, activation='softmax', name = 'fc' + str(n_classes), kernel_initializer = 'he_uniform')(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name = 'ResNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(\"../logs/ResNet-iceberg-relu-20-epochs-batch-16-augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)\n",
    "\n",
    "test_datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size = 24)\n",
    "\n",
    "validation_generator = test_datagen.flow(X_val, y_val, batch_size = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit_generator(train_generator,\n",
    "#                            steps_per_epoch = 3000,\n",
    "#                            epochs = 2,\n",
    "#                            verbose = 1,\n",
    "#                            validation_data = validation_generator,\n",
    "#                            validation_steps = 1500)\n",
    "#                            callbacks = [tensorboard])\n",
    "\n",
    "model.fit(X_train_cv, y_train_cv,\n",
    "          batch_size = 16,\n",
    "          epochs = 3,\n",
    "          verbose = 1,\n",
    "          validation_data = (X_valid, y_valid))\n",
    "#           callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_val, y_val, verbose = 1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "# X_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "# X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis],\n",
    "#                         X_band_test_2[:, :, :, np.newaxis],\n",
    "#                         ((X_band_test_1 + X_band_test_2) / 2)[:, :, :, np.newaxis]], axis = -1)\n",
    "\n",
    "# predicted_test = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame()\n",
    "# submission['id'] = test['id']\n",
    "# submission['is_iceberg'] = predicted_test.reshape((predicted_test.shape[0]))\n",
    "# submission.to_csv('kaggle/results/iceberg/submission-cnn-iceberg-relu-20-epochs-batch-16-augmentation.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
