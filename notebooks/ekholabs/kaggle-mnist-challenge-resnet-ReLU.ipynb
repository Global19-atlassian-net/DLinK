{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle MNIST Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Deep Residual Neural Network to classify digits for the Kaggle MNIST challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "\n",
    "raw_data = np.loadtxt('kaggle/datasets/mnist/train.csv', skiprows=1, dtype='int', delimiter=',')\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    raw_data[:,1:], raw_data[:,0], test_size = 0.1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")/255.\n",
    "X_val = X_val.astype(\"float32\")/255.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, n_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Identity Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, main_path_shape, filters, stage, block):    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    # Kernel Size is (1, 1), or just 1\n",
    "    # Default strides is (1, 1)\n",
    "    X = Conv2D(F1, kernel_size = 1, padding = 'valid', name = conv_name_base + '2a', kernel_initializer = 'glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    # Kernel Size is (main_path_shape, main_path_shape)\n",
    "    # Default strides is (1, 1)\n",
    "    X = Conv2D(F2, kernel_size = main_path_shape, padding = 'same', name = conv_name_base + '2b', kernel_initializer = 'glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    # Default strides is (1, 1)\n",
    "    X = Conv2D(F3, kernel_size = 1, padding = 'valid', name = conv_name_base + '2c', kernel_initializer = 'glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Convolutional Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, main_path_shape, filters, stage, block, s = 2):    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, kernel_size = 1, strides = s, name = conv_name_base + '2a', kernel_initializer = 'glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(F2, kernel_size = main_path_shape, padding = 'same', name = conv_name_base + '2b', kernel_initializer = 'glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(F3, kernel_size = 1, padding = 'valid', name = conv_name_base + '2c', kernel_initializer = 'glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, kernel_size = 1, strides = s, padding = 'valid', name = conv_name_base + '1', kernel_initializer = 'glorot_uniform')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetE(input_shape = (28, 28, 1)):\n",
    "    \"\"\"\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK -> CONVBLOCK -> IDBLOCK\n",
    "    -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FC -> SOFTMAX\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(16, kernel_size = 5, strides = 2, name = 'conv1', kernel_initializer = 'glorot_uniform')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size = 3, strides = (2, 2))(X)\n",
    "    \n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [32, 64, 64], stage = 2, block = 'a', s = 1)\n",
    "    X = identity_block(X, 3, [32, 64, 64], stage = 2, block = 'b')\n",
    "    \n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [64, 64, 128], stage = 3, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [64, 64, 128], stage = 3, block = 'b')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [128, 128, 256], stage = 4, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='d')\n",
    "    X = identity_block(X, 3, [128, 128, 256], stage = 4, block='e')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, main_path_shape = 3, filters = [265, 256, 512], stage = 5, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'b')\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'c')\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'd')\n",
    "    X = identity_block(X, 3, [265, 256, 512], stage = 5, block = 'e')\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D(pool_size = 1, name = 'avg_pool')(X)\n",
    "    \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(n_classes, activation='softmax', name = 'fc' + str(n_classes), kernel_initializer = 'glorot_uniform')(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name = 'ResNetE')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetE()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)\n",
    "\n",
    "test_datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size = 32)\n",
    "\n",
    "validation_generator = test_datagen.flow(X_val, y_val, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(\"../logs/resnet-mnist-meetup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch = 3000,\n",
    "                           epochs = 30,\n",
    "                           verbose = 1,\n",
    "                           validation_data = validation_generator,\n",
    "                           validation_steps = 1500,\n",
    "                           callbacks = [annealer, tensorboard])\n",
    "\n",
    "# hist = model.fit(X_train, y_train, batch_size = 32,\n",
    "#                            epochs = 40,\n",
    "#                            verbose = 1,\n",
    "#                            validation_split = 0.1,\n",
    "#                            callbacks=[annealer, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss, final_acc = model.evaluate(X_val, y_val, verbose = 1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.loadtxt('kaggle/datasets/mnist/test.csv', skiprows=1, dtype='int', delimiter=',')\n",
    "# X_test = X_test.reshape(28000, 28, 28, 1).astype('float32') / 255.\n",
    "\n",
    "# predictions = model.predict(X_test, verbose = 2)\n",
    "# predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "# pd.DataFrame({\"ImageId\": list(range(1, len(predictions) + 1)), \"Label\": predictions}).to_csv('kaggle/results/mnist/submission-ReLU-30-epochs-batch-32-ResNet-E-data-augmentation.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
