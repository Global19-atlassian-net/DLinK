{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle MNIST Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Deep Convolutional Neural Network to classify digits for the Kaggle MNIST challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Add, Dense, Dropout\n",
    "from keras.layers import Flatten, AveragePooling2D, MaxPooling2D, Conv2D, Activation, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras_contrib.layers.advanced_activations import SineReLU\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "\n",
    "raw_data = np.loadtxt('kaggle/datasets/mnist/train.csv', skiprows=1, dtype='int', delimiter=',')\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    raw_data[:,1:], raw_data[:,0], test_size = 0.2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")/255.\n",
    "X_val = X_val.astype(\"float32\")/255.\n",
    "X_test = X_test.astype(\"float32\")/255.\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/multi-conv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.0025\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(28, 7, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(Conv2D(28, 7, padding = 'same'))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, 3, padding = 'same'))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(Conv2D(32, 3, padding = 'same'))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(44, 2, padding = 'same'))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(Conv2D(44, 2, padding = 'same'))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(Conv2D(48, 2))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(SineReLU(epsilon))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)\n",
    "\n",
    "test_datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size = 64)\n",
    "\n",
    "validation_generator = test_datagen.flow(X_val, y_val, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = ModelCheckpoint(monitor='val_acc', filepath=output_dir+'/weights-cnn-mnist.hdf5', save_best_only=True, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', mode='max', patience=3)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(\"../logs/cnn-mnist-ReLUs-30-epochs-EkhoNet8-data-augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           steps_per_epoch = 3500,\n",
    "                           epochs = 15,\n",
    "                           verbose = 1,\n",
    "                           validation_data = validation_generator,\n",
    "                           validation_steps = 3500,\n",
    "                           callbacks = [modelCheckpoint, earlyStopping])#, annealer, tensorboard])\n",
    "\n",
    "# hist = model.fit(X_train, y_train, batch_size = 32,\n",
    "#                            epochs = 40,\n",
    "#                            verbose = 1,\n",
    "#                            validation_split = 0.1,\n",
    "#                            callbacks=[annealer, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero indexed -> get the epoch with highest accuracy.\n",
    "saved_model = keras.models.load_model(output_dir + '/weights-cnn-mnist.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss, final_acc = saved_model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sub = np.loadtxt('kaggle/datasets/mnist/test.csv', skiprows=1, dtype='int', delimiter=',')\n",
    "X_test_sub = X_test_sub.reshape(28000, 28, 28, 1).astype('float32') / 255.\n",
    "\n",
    "predictions = model.predict(X_test_sub, verbose = 2)\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "pd.DataFrame({\"ImageId\": list(range(1, len(predictions) + 1)), \"Label\": predictions}).to_csv('kaggle/results/mnist/submission-ReLUs-30-epochs-EkhoNet8-data-augmentation.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
