{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM for Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Conv Net performs sentiment analysis on the Google toxicity dataset review dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.layers import Embedding, Conv1D, SpatialDropout1D, GlobalMaxPool1D, LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/bi-lstm'\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 64\n",
    "test_split=.1\n",
    "\n",
    "n_dim = 32\n",
    "n_unique_words = 20000\n",
    "max_review_length = 300\n",
    "pad_type = trunc_type = 'pre'\n",
    "\n",
    "n_bilstm_1 = 8\n",
    "n_bilstm_2 = 16\n",
    "drop_bilstm = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('kaggle/datasets/toxicity/train.csv')\n",
    "test_df = pd.read_csv('kaggle/datasets/toxicity/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_series = train_df['comment_text'].fillna(\"_\").values\n",
    "test_sentences_series = test_df['comment_text'].fillna(\"_\").values\n",
    "\n",
    "# Tokeninze the Training data\n",
    "tokenizer = text.Tokenizer(num_words=n_unique_words)\n",
    "tokenizer.fit_on_texts(list(train_sentences_series))\n",
    "train_tokenized_sentences = tokenizer.texts_to_sequences(train_sentences_series)\n",
    "\n",
    "# Tokeninze the Test data\n",
    "test_tokenized_sentences = tokenizer.texts_to_sequences(test_sentences_series)\n",
    "\n",
    "# toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
    "classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y_train = train_df[classes].values\n",
    "\n",
    "X_train = pad_sequences(train_tokenized_sentences, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "X_test_sub = pad_sequences(test_tokenized_sentences, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Activiation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "class ReLUs(Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(ReLUs, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'ReLU_s'\n",
    "\n",
    "def relus(Z):\n",
    "    e_param = 1.8\n",
    "    pi = K.variable((3.14))\n",
    "    m = e_param + (K.sigmoid(K.sin(Z)) - K.sigmoid(K.cos(Z)) * K.exp(K.sqrt(pi)))\n",
    "    A = K.maximum(m, Z)\n",
    "    return A\n",
    "\n",
    "get_custom_objects().update({'ReLU_s': ReLUs(relus)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design Deep Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(max_review_length,), dtype='int16', name='input')\n",
    "embedding_layer = Embedding(n_unique_words, n_dim, input_length=max_review_length,\n",
    "                            name='embedding_1')(input_layer)\n",
    "\n",
    "bi_lstm_1 = Bidirectional(LSTM(n_bilstm_1, dropout=drop_bilstm, return_sequences=True,\n",
    "                               name='bi_lstm_1'))(embedding_layer)\n",
    "bi_lstm_2 = Bidirectional(LSTM(n_bilstm_2, dropout=drop_bilstm, return_sequences=True,\n",
    "                               name='bi_lstm_2'))(embedding_layer)\n",
    "\n",
    "concat = concatenate([bi_lstm_1, bi_lstm_2])\n",
    "\n",
    "densor = Dense(64, activation=\"relu\")(concat)\n",
    "\n",
    "flat = Flatten()(densor)\n",
    "\n",
    "output = Dense(n_classes, activation='softmax', name='output')(flat)\n",
    "\n",
    "model = Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = ModelCheckpoint(filepath=output_dir+'/weights-bi-lstm-toxicity_new.hdf5', save_best_only=True, mode='min')\n",
    "earlyStopping = EarlyStopping(mode='min', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_valid, y_valid), callbacks=[modelCheckpoint, earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(output_dir+'/weights-multicnn-toxicity.hdf5')\n",
    "model = keras.models.load_model(output_dir + '/weights-bi-lstm-toxicity_new.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(y_hat)\n",
    "pct_auc = roc_auc_score(y_valid, y_hat[0:31915]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'{:0.2f}'.format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"kaggle/datasets/toxicity/sample_submission.csv\")\n",
    "\n",
    "sample_submission.shape\n",
    "\n",
    "sample_submission[classes] = y_hat\n",
    "sample_submission.to_csv(\"kaggle/datasets/toxicity/submission_bi-lstm_relus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
