{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Word Vectors with word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show, figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to lack of resources, I'm not working with the full Gutenberg dataset (18 books).\n",
    "gberg_sent_tokens = sent_tokenize(gutenberg.raw(fileids=['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'carroll-alice.txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.',\n",
       " \"She was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.\",\n",
       " 'Her mother\\nhad died too long ago for her to have more than an indistinct\\nremembrance of her caresses; and her place had been supplied\\nby an excellent woman as governess, who had fallen little short\\nof a mother in affection.',\n",
       " \"Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\\nless as a governess than a friend, very fond of both daughters,\\nbut particularly of Emma.\",\n",
       " 'Between _them_ it was more the intimacy\\nof sisters.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gberg_sent_tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"She was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gberg_sent_tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She',\n",
       " 'was',\n",
       " 'the',\n",
       " 'youngest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'two',\n",
       " 'daughters',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'affectionate',\n",
       " ',',\n",
       " 'indulgent',\n",
       " 'father',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " ',',\n",
       " 'in',\n",
       " 'consequence',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sister',\n",
       " \"'s\",\n",
       " 'marriage',\n",
       " ',',\n",
       " 'been',\n",
       " 'mistress',\n",
       " 'of',\n",
       " 'his',\n",
       " 'house',\n",
       " 'from',\n",
       " 'a',\n",
       " 'very',\n",
       " 'early',\n",
       " 'period',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(gberg_sent_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(gberg_sent_tokens[1])[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to lack of resources, I'm not working with the full Gutenberg dataset (18 books).\n",
    "gberg_sents = gutenberg.sents(fileids=['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'carroll-alice.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'],\n",
       " ['VOLUME', 'I'],\n",
       " ['CHAPTER', 'I'],\n",
       " ['Emma',\n",
       "  'Woodhouse',\n",
       "  ',',\n",
       "  'handsome',\n",
       "  ',',\n",
       "  'clever',\n",
       "  ',',\n",
       "  'and',\n",
       "  'rich',\n",
       "  ',',\n",
       "  'with',\n",
       "  'a',\n",
       "  'comfortable',\n",
       "  'home',\n",
       "  'and',\n",
       "  'happy',\n",
       "  'disposition',\n",
       "  ',',\n",
       "  'seemed',\n",
       "  'to',\n",
       "  'unite',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'best',\n",
       "  'blessings',\n",
       "  'of',\n",
       "  'existence',\n",
       "  ';',\n",
       "  'and',\n",
       "  'had',\n",
       "  'lived',\n",
       "  'nearly',\n",
       "  'twenty',\n",
       "  '-',\n",
       "  'one',\n",
       "  'years',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'with',\n",
       "  'very',\n",
       "  'little',\n",
       "  'to',\n",
       "  'distress',\n",
       "  'or',\n",
       "  'vex',\n",
       "  'her',\n",
       "  '.'],\n",
       " ['She',\n",
       "  'was',\n",
       "  'the',\n",
       "  'youngest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'two',\n",
       "  'daughters',\n",
       "  'of',\n",
       "  'a',\n",
       "  'most',\n",
       "  'affectionate',\n",
       "  ',',\n",
       "  'indulgent',\n",
       "  'father',\n",
       "  ';',\n",
       "  'and',\n",
       "  'had',\n",
       "  ',',\n",
       "  'in',\n",
       "  'consequence',\n",
       "  'of',\n",
       "  'her',\n",
       "  'sister',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'marriage',\n",
       "  ',',\n",
       "  'been',\n",
       "  'mistress',\n",
       "  'of',\n",
       "  'his',\n",
       "  'house',\n",
       "  'from',\n",
       "  'a',\n",
       "  'very',\n",
       "  'early',\n",
       "  'period',\n",
       "  '.']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gberg_sents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gberg_sents[4][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466284"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Due to lack of resources, I'm not working with the full Gutenberg dataset (18 books).\n",
    "len(gutenberg.words(fileids=['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'carroll-alice.txt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size == dimensions\n",
    "# window 10: 20 context words, 10 to the left and 10 to the right\n",
    "model = Word2Vec(sentences=gberg_sents, size=64, sg=1, window=10, min_count=5, seed=42, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't have to save the model if we don't want to. It's being done here as demonstration.\n",
    "model.save('raw_gutenberg_model.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('raw_gutenberg_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43951929,  0.20345363, -0.12350496, -0.22693247,  0.13012436,\n",
       "        0.43263096, -0.06086079, -0.28693768,  0.03658728, -0.16363265,\n",
       "        0.08530718,  0.17591736,  0.02361562, -0.12141223,  0.19483131,\n",
       "       -0.12127479, -0.3244608 ,  0.76228642,  0.12957637, -0.40177354,\n",
       "        0.10379501, -0.20748216, -0.10074964, -0.21412633,  0.14703584,\n",
       "        0.05053272, -0.01361896,  0.10677844,  0.40056241, -0.0289387 ,\n",
       "        0.10345098,  0.31935829,  0.07284847, -0.09583906,  0.34848803,\n",
       "       -0.49537802,  0.18112972, -0.3836998 ,  0.10134034,  0.11419357,\n",
       "        0.63601786, -0.12048271,  0.28826013,  0.25589827,  0.17686081,\n",
       "       -0.11655235, -0.09858518,  0.07610506,  0.27675855,  0.12048908,\n",
       "       -0.13589375,  0.37858659, -0.1755271 , -0.07064102, -0.38758591,\n",
       "        0.02026783,  0.26397982, -0.09220792, -0.06000375,  0.17543206,\n",
       "       -0.18837382, -0.09307611, -0.14029233, -0.04388688], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['house']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model['house'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Place', 0.811130166053772),\n",
       " ('shop', 0.8057742714881897),\n",
       " ('dining', 0.7984946966171265),\n",
       " ('Camden', 0.793912410736084),\n",
       " ('drove', 0.7894566059112549),\n",
       " ('card', 0.7870776057243347),\n",
       " ('carriages', 0.7848575115203857),\n",
       " ('landau', 0.7848074436187744),\n",
       " ('doors', 0.7846565246582031),\n",
       " ('dressing', 0.7832915782928467)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grant', 0.8283084630966187),\n",
       " ('agree', 0.816801905632019),\n",
       " ('manage', 0.8121541738510132),\n",
       " ('deny', 0.8087695837020874),\n",
       " ('expect', 0.8077518939971924),\n",
       " ('pretend', 0.8055640459060669),\n",
       " ('hesitate', 0.8037261962890625),\n",
       " ('forgive', 0.7959498167037964),\n",
       " ('venture', 0.7946842312812805),\n",
       " ('suppose', 0.7916132211685181)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('think')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('evening', 0.8378722071647644),\n",
       " ('morning', 0.8360257744789124),\n",
       " ('night', 0.7744661569595337),\n",
       " ('month', 0.7601619958877563),\n",
       " ('spend', 0.7497485876083374),\n",
       " ('next', 0.7461041212081909),\n",
       " ('Box', 0.7449760437011719),\n",
       " ('week', 0.7388782501220703),\n",
       " ('afternoon', 0.7373006343841553),\n",
       " ('Saturday', 0.7325820922851562)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.8715599775314331),\n",
       " ('aunt', 0.8328174352645874),\n",
       " ('brother', 0.8229626417160034),\n",
       " ('husband', 0.8143963813781738),\n",
       " ('wishes', 0.8131052851676941),\n",
       " ('sister', 0.8092051148414612),\n",
       " ('sake', 0.7808470129966736),\n",
       " ('Isabella', 0.7767211198806763),\n",
       " ('uncle', 0.7749599814414978),\n",
       " ('daughter', 0.7736835479736328)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('father')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'house'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match('mother father daughter house'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52142599915970789"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('father', 'house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.7976123690605164),\n",
       " ('husband', 0.7698510885238647),\n",
       " ('sister', 0.7507162094116211),\n",
       " ('aunt', 0.7425578832626343),\n",
       " ('wishes', 0.7321113348007202),\n",
       " ('friend', 0.7317440509796143),\n",
       " ('daughter', 0.7195297479629517),\n",
       " ('nurse', 0.7042011618614197),\n",
       " ('sake', 0.6932041645050049),\n",
       " ('affections', 0.6879606246948242)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['father', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('law', 0.7740381956100464),\n",
       " ('daughter', 0.7688101530075073),\n",
       " ('Wallis', 0.7640249729156494),\n",
       " ('friend', 0.7596955299377441),\n",
       " ('brother', 0.7563303709030151),\n",
       " ('nurse', 0.7447747588157654),\n",
       " ('husband', 0.744299054145813),\n",
       " ('eldest', 0.7153913974761963),\n",
       " ('Harville', 0.7145655155181885),\n",
       " ('daughters', 0.7111117243766785)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['son', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sister', 0.752424955368042),\n",
       " ('friend', 0.7332223653793335),\n",
       " ('father', 0.726719319820404),\n",
       " ('mother', 0.7208641767501831),\n",
       " ('nurse', 0.7087678909301758),\n",
       " ('daughter', 0.7065379619598389),\n",
       " ('wishes', 0.7026852369308472),\n",
       " ('particularly', 0.6882469654083252),\n",
       " ('patience', 0.6876028776168823),\n",
       " ('wishing', 0.6839585304260254)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['husband', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.7976123690605164),\n",
       " ('husband', 0.7698510885238647),\n",
       " ('sister', 0.7507162094116211),\n",
       " ('aunt', 0.7425578832626343),\n",
       " ('wishes', 0.7321113348007202),\n",
       " ('friend', 0.7317440509796143),\n",
       " ('daughter', 0.7195297479629517),\n",
       " ('nurse', 0.7042011618614197),\n",
       " ('sake', 0.6932041645050049),\n",
       " ('affections', 0.6879606246948242),\n",
       " ('brother', 0.6861639618873596),\n",
       " ('Isabella', 0.6848157048225403),\n",
       " ('rights', 0.6789318323135376),\n",
       " ('patience', 0.678371787071228),\n",
       " ('neighbour', 0.673454225063324),\n",
       " ('exertions', 0.6703362464904785),\n",
       " ('intentions', 0.6690245866775513),\n",
       " ('health', 0.6670863032341003),\n",
       " ('blind', 0.6649085283279419),\n",
       " ('heart', 0.6615605354309082),\n",
       " ('excuses', 0.6606819033622742),\n",
       " ('mistress', 0.658902645111084),\n",
       " ('own', 0.6567113399505615),\n",
       " ('kindness', 0.6549253463745117),\n",
       " ('care', 0.6526315212249756),\n",
       " ('companion', 0.6516454815864563),\n",
       " ('daughters', 0.6496641635894775),\n",
       " ('sons', 0.646655797958374),\n",
       " ('uneasy', 0.646139919757843),\n",
       " ('law', 0.6459567546844482)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['father', 'woman'], negative=['man'], topn=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce word vector dimensionality with t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-Distributed Stochastic Name Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4417"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model[model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2d = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df = pd.DataFrame(X_2d, columns=['x', 'y'])\n",
    "coords_df['token'] = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df.to_csv('raw_gutenberg_tsne.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise 2D representation of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coorrds_df = pd.read_csv('raw_gutenberg_tsne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = coords_df.plot.scatter('x', 'y', figsize=(8,8), marker='o', s=10, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = coords_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width=600, plot_height=600)\n",
    "_ = p.text(x=subset_df.x, y=subset_df.y, text=subset_df.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
